---
layout: post
title: Blog Post 3 - Fake News Classification
---

> In this blog post, I'll create a machine learning model for classifying fake news using *Tensorflow* supported by python. By using the python dataset, we'll use the general format of kaggle dataset created by python.

## Preparation: Import Packages

Before all, want to first import necessary python packages for the model creation

```python
import numpy as np
import pandas as pd
import tensorflow as tf
import re
import string

from tensorflow.keras import layers
from tensorflow.keras import losses

# requires update to tensorflow 2.4
# >>> conda activate PIC16B
# >>> pip install tensorflow==2.4
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# for embedding viz
import plotly.express as px 
import plotly.io as pio
pio.templates.default = "plotly_white"

# Part II imports
import tensorflow as tf
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords



# Part V imports
from sklearn.decomposition import PCA
import plotly.express as px

from plotly.io import write_html
```

## Part I: Acquire Training Data

First, acquire the training data from the url provided below stored inside the variable `train_url`.

```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df  = pd.read_csv(train_url)
```

Now, visualize the dataset. The dataset should have three main contents with lots of observations. Each observation represents a piece of news. The three useful contents of the dataset are:

- title: the title of the news piece

- text: the main content / text of the news piece

- fake: tell whether the news is fake (0: not fake, 1: fake)

The dataset is visualized as follows:

```python
df.head()
```
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <th>17366</th>
      <th>Merkel: Strong result for Austria's FPO 'big c...</th>
      <th>German Chancellor Angela Merkel said on Monday...</th>
      <th>0</th>
    </tr>
    <tr>
      <th>1</th>
      <th>5634</th>
      <th>Trump says Pence will lead voter fraud panel</th>
      <th>WEST PALM BEACH, Fla.President Donald Trump sa...</th>
    </tr>
    <tr>
      <th>2</th>
      <th>17487</th>
      <th>JUST IN: SUSPECTED LEAKER and â€œClose Confidant...</th>
      <th>On December 5, 2017, Circa s Sara Carter warne...</th>
      <th>1</th>
    </tr>
    <tr>
      <th>3</th>
      <th>12217</th>
      <th>Thyssenkrupp has offered help to Argentina ove...</th>
      <th>Germany s Thyssenkrupp, has offered assistance...</th>
      <th>0</th>
    </tr>
    <tr>
      <th>4</th>
      <th>5535</th>
      <th>Trump say appeals court decision on travel ban...</th>
      <th>President Donald Trump on Thursday called the ...</th>
      <th>0</th>
    </tr>
  </tbody>
</table>
</div>

## Part II: Data Preparation

### 2.1 Prepare and Create Tensorflow Dataset

### 2.2 Train-Validation Separation

## Part III: Model Creation and Comparison

### 3.1 Model 1: Title-Only Analysis

```python

```

```python

````

### 3.2 Model 2: Text-Only Analysis

### 3.3 Model 3: Title-Text Analysis

## Part IV: Model Evaluation

Before all, import the test dataset for evaluation

```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
df_test  = pd.read_csv(test_url)
test = make_dataset(df_test)
```

### 4.1 Evaluation for Title-Only Model
```python
titles_model.evaluate(test)
```
```
225/225 [==============================] - 1s 3ms/step - loss: 0.1450 - accuracy: 0.9432
[0.14499153196811676, 0.9432045817375183]
```

### 4.2 Evaluation for Text-Only Model 
```python
texts_model.evaluate(test)
```
```
225/225 [==============================] - 3s 12ms/step - loss: 0.0570 - accuracy: 0.9848
[0.0569567047059536, 0.9848099946975708]
```

### 4.3 Evaluation for Title-Text Model
```python
combined_model.evaluate(test)
```

```
225/225 [==============================] - 3s 13ms/step - loss: 0.0402 - accuracy: 0.9897
[0.04015771672129631, 0.9897100329399109]
```

## Part V: Embeddings

```python
title_weights = combined_model.get_layer('titles').get_weights()[0] # get the weights from the titles layer
text_weights = combined_model.get_layer('texts').get_weights()[0] # get the weights from the texts layer
vocab = vectorize_layer.get_vocabulary()
```

```python
def embedding_plot(weights):

  pca = PCA(n_components=2)
  weights = pca.fit_transform(weights)

  embedding_df = pd.DataFrame({
      'word' : vocab, 
      'x0'   : weights[:,0],
      'x1'   : weights[:,1]
  })

  fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 size = list(np.ones(len(embedding_df))),
                 size_max = 2,
                 hover_name = "word")
  return fig
```

```python
title_fig = embedding_plot(title_weights)
text_fig = embedding_plot(text_weights)
```

```python
write_html(title_fig, "title_fig.html")
```
{% include BP3_title_fig.html %}

```python
write_html(text_fig, "text_fig.html")
```
{% include BP3_text_fig.html %}
